{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBQXlz7dH1mB"
      },
      "source": [
        "# 20878 - COMPUTER VISION AND IMAGE PROCESSING\n",
        "\n",
        "---\n",
        "\n",
        "## Feedforward Neural Networks\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MnEfJWqfX_yxIQroqZ6gh6adbSMeX91G\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXAtVU3WwBDq",
        "outputId": "1d3feb3c-8081-46e5-d6bc-7584f8b5d810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.100-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting cvzone\n",
            "  Downloading cvzone-1.6.1.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.100-py3-none-any.whl (977 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m977.1/977.1 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Building wheels for collected packages: cvzone\n",
            "  Building wheel for cvzone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvzone: filename=cvzone-1.6.1-py3-none-any.whl size=26298 sha256=1c1e2379d92a518883c1db4c0ea42519ffe8433c609a63a44bab46018384cb41\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/36/ec/47be2d4e59dc4289e684d5b0dde54d1e72e51a614e57690e85\n",
            "Successfully built cvzone\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, cvzone, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed cvzone-1.6.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.100 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics opencv-python cvzone matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94cjocQ6xFWf",
        "outputId": "63e016de-b584-4f7f-ebbd-e269c2a16d64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL6a3eNVIaRs"
      },
      "source": [
        "### 🌐 Connect Colab to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz65i0yOHzlK",
        "outputId": "5379f621-e243-488a-d8a8-63ef5053a9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, clear_output\n",
        "import math\n",
        "import time\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjYmCvaLIfUg"
      },
      "source": [
        "### ⚙️ Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5AsiXck_aGnM"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/cards'\n",
        "\n",
        "# Define paths\n",
        "DATA_YAML_PATH = os.path.join(BASE_DIR, 'absolute_data.yaml')\n",
        "OUTPUT_DIR = os.path.join(BASE_DIR, 'models')\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqshLIUDzoEs",
        "outputId": "9eab84d2-ee89-4bcd-cdfb-368c69fe55cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated YAML file created at: /content/drive/MyDrive/cards/colab_data.yaml\n",
            "New paths:\n",
            "Train: /content/drive/MyDrive/cards/dataset/train/images\n",
            "Validation: /content/drive/MyDrive/cards/dataset/valid/images\n",
            "Test: /content/drive/MyDrive/cards/dataset/test/images\n"
          ]
        }
      ],
      "source": [
        "# Run this code cell to update your data.yaml file for Google Colab\n",
        "# Make sure Google Drive is mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Path to your original YAML file\n",
        "original_yaml_path = '/content/drive/MyDrive/cards/absolute_data.yaml'\n",
        "\n",
        "# Load the YAML file\n",
        "with open(original_yaml_path, 'r') as f:\n",
        "    data = yaml.safe_load(f)\n",
        "\n",
        "# Update the paths to match your Google Drive structure\n",
        "data['train'] = '/content/drive/MyDrive/cards/dataset/train/images'\n",
        "data['val'] = '/content/drive/MyDrive/cards/dataset/valid/images'\n",
        "data['test'] = '/content/drive/MyDrive/cards/dataset/test/images'\n",
        "\n",
        "# Create a new YAML file\n",
        "updated_yaml_path = '/content/drive/MyDrive/cards/colab_data.yaml'\n",
        "with open(updated_yaml_path, 'w') as f:\n",
        "    yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "print(f\"Updated YAML file created at: {updated_yaml_path}\")\n",
        "print(\"New paths:\")\n",
        "print(f\"Train: {data['train']}\")\n",
        "print(f\"Validation: {data['val']}\")\n",
        "print(f\"Test: {data['test']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31UScbipQSRw"
      },
      "source": [
        "### ⏳ Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG8AKgFlQQgg",
        "outputId": "29bbbc39-b124-415d-f15e-991324483b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with data config: /content/drive/MyDrive/cards/colab_data.yaml\n",
            "Ultralytics 8.3.100 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/drive/MyDrive/cards/colab_data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/cards/models, name=card_detection2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/cards/models/card_detection2\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 79.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=52\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,020,988 parameters, 3,020,972 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/cards/models/card_detection2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 271MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/cards/dataset/train/labels... 964 images, 0 backgrounds, 0 corrupt: 100%|██████████| 964/964 [13:49<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/cards/dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/cards/dataset/valid/labels... 193 images, 0 backgrounds, 0 corrupt: 100%|██████████| 193/193 [02:41<00:00,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/cards/dataset/valid/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/cards/models/card_detection2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/cards/models/card_detection2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      2.28G     0.8377      4.453      1.166         30        640: 100%|██████████| 61/61 [00:26<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820    0.00878    0.00354    0.00549    0.00537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      2.48G     0.6832      3.979      1.053         22        640: 100%|██████████| 61/61 [00:23<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820     0.0275      0.825     0.0672     0.0604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50      2.48G     0.6898      3.549      1.083         33        640: 100%|██████████| 61/61 [00:23<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.182      0.272       0.13      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      2.48G     0.7101      3.129      1.115         27        640: 100%|██████████| 61/61 [00:22<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.241      0.433      0.234      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      2.49G     0.7245      2.751      1.147         47        640: 100%|██████████| 61/61 [00:22<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.258      0.577      0.352      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      2.49G     0.7104      2.445      1.157         38        640: 100%|██████████| 61/61 [00:23<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.347      0.653      0.479       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50       2.5G     0.6958      2.261      1.146         34        640: 100%|██████████| 61/61 [00:23<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820       0.43      0.685      0.565      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50       2.5G     0.6652      2.081      1.111         25        640: 100%|██████████| 61/61 [00:22<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.497      0.735      0.645      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50       2.5G     0.6556      1.934      1.105         34        640: 100%|██████████| 61/61 [00:23<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.559      0.806      0.736      0.652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50       2.5G     0.6508      1.805        1.1         37        640: 100%|██████████| 61/61 [00:25<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.713      0.784      0.817      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50       2.5G      0.645      1.698      1.094         26        640: 100%|██████████| 61/61 [00:24<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.699      0.831      0.855      0.762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50       2.5G     0.6339      1.566      1.079         40        640: 100%|██████████| 61/61 [00:24<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.753      0.824      0.866      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50       2.5G      0.617      1.472       1.07         46        640: 100%|██████████| 61/61 [00:24<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.768      0.879      0.915      0.815\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      2.51G     0.6037      1.347      1.058         39        640: 100%|██████████| 61/61 [00:24<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820       0.81       0.88      0.919      0.822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50      2.51G     0.5984       1.31      1.059         54        640: 100%|██████████| 61/61 [00:24<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.867      0.894      0.942      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      2.51G     0.5893      1.237      1.043         31        640: 100%|██████████| 61/61 [00:24<00:00,  2.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.808      0.918      0.939      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      2.53G     0.5753      1.187      1.033         32        640: 100%|██████████| 61/61 [00:24<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.898      0.905      0.956      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      2.53G     0.5711       1.14      1.035         40        640: 100%|██████████| 61/61 [00:24<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.903      0.902      0.959      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      2.55G     0.5676      1.087      1.023         39        640: 100%|██████████| 61/61 [00:25<00:00,  2.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.934      0.914      0.966      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      2.55G     0.5819      1.069      1.039         27        640: 100%|██████████| 61/61 [00:24<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.905      0.913      0.966      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      2.55G     0.5598      1.028      1.019         41        640: 100%|██████████| 61/61 [00:23<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820       0.93      0.941      0.976      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      2.55G     0.5611      1.008      1.023         33        640: 100%|██████████| 61/61 [00:27<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.944      0.942      0.978       0.88\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      2.55G     0.5564     0.9641      1.026         51        640: 100%|██████████| 61/61 [00:23<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.917      0.957      0.978      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      2.55G     0.5577     0.9532      1.018         32        640: 100%|██████████| 61/61 [00:26<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.953      0.947       0.98      0.886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50      2.57G     0.5418     0.9316      1.005         26        640: 100%|██████████| 61/61 [00:25<00:00,  2.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.955      0.946      0.984      0.884\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      2.58G     0.5489     0.8899      1.015         30        640: 100%|██████████| 61/61 [00:23<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.958      0.955      0.983      0.885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50      2.58G     0.5586     0.8939       1.02         38        640: 100%|██████████| 61/61 [00:24<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.944      0.952      0.981      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      2.58G     0.5407     0.8848      1.009         36        640: 100%|██████████| 61/61 [00:24<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.955      0.953      0.985      0.891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50       2.6G     0.5375     0.8555          1         49        640: 100%|██████████| 61/61 [00:25<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.969      0.961      0.987      0.889\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50       2.6G      0.538     0.8546      1.002         35        640: 100%|██████████| 61/61 [00:22<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.972      0.954      0.985      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      2.62G     0.5423     0.8527      1.008         28        640: 100%|██████████| 61/61 [00:22<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.967      0.968      0.987       0.89\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      2.62G     0.5393      0.823      1.008         37        640: 100%|██████████| 61/61 [00:22<00:00,  2.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.967      0.964      0.988      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50      2.62G     0.5295     0.8091     0.9988         44        640: 100%|██████████| 61/61 [00:22<00:00,  2.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.974      0.959      0.987      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50      2.62G     0.5335     0.8021     0.9989         45        640: 100%|██████████| 61/61 [00:22<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.965       0.96      0.988      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50      2.62G     0.5296     0.7999      0.994         44        640: 100%|██████████| 61/61 [00:23<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.955      0.976      0.989      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50      2.62G     0.5205     0.7804     0.9953         22        640: 100%|██████████| 61/61 [00:22<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.972      0.966      0.989      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50      2.62G     0.5176     0.7724     0.9937         29        640: 100%|██████████| 61/61 [00:24<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.979      0.965      0.989      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50      2.62G     0.5293      0.796     0.9992         40        640: 100%|██████████| 61/61 [00:24<00:00,  2.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.964      0.975      0.988      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50      2.62G      0.522      0.764     0.9886         41        640: 100%|██████████| 61/61 [00:25<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  3.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.977      0.965       0.99      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50      2.62G     0.5186     0.7744     0.9915         49        640: 100%|██████████| 61/61 [00:23<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.971      0.969      0.988      0.895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50      2.62G     0.4551     0.7031     0.9691         15        640: 100%|██████████| 61/61 [00:25<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.971      0.966      0.987      0.891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50      2.62G     0.4438     0.6408     0.9622         17        640: 100%|██████████| 61/61 [00:22<00:00,  2.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.974      0.969      0.989      0.892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      2.62G      0.437     0.6284     0.9571         16        640: 100%|██████████| 61/61 [00:23<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.972      0.972      0.989      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50      2.62G     0.4327     0.6097     0.9511         17        640: 100%|██████████| 61/61 [00:23<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.977      0.966       0.99      0.896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50      2.62G     0.4287      0.598     0.9454         18        640: 100%|██████████| 61/61 [00:23<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.973      0.966      0.989      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50      2.62G     0.4303     0.5982     0.9572         16        640: 100%|██████████| 61/61 [00:23<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.979      0.972      0.989      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      2.62G     0.4278     0.5951     0.9499         18        640: 100%|██████████| 61/61 [00:22<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.977      0.969      0.989      0.895\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      2.62G     0.4247     0.5876     0.9497         18        640: 100%|██████████| 61/61 [00:21<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.981      0.966      0.989      0.896\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      2.62G     0.4224     0.5852     0.9451         17        640: 100%|██████████| 61/61 [00:23<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.978      0.966      0.989      0.897\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50      2.62G     0.4252     0.5865     0.9506         17        640: 100%|██████████| 61/61 [00:21<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:02<00:00,  2.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820       0.98      0.966      0.989      0.898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 0.388 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/cards/models/card_detection2/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/drive/MyDrive/cards/models/card_detection2/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/drive/MyDrive/cards/models/card_detection2/weights/best.pt...\n",
            "Ultralytics 8.3.100 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,015,788 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        193        820      0.977      0.965       0.99      0.899\n",
            "                    2C         17         17      0.987          1      0.995       0.88\n",
            "                    2D         15         15          1       0.93      0.995      0.891\n",
            "                    2H         18         18          1      0.932      0.992       0.96\n",
            "                    2S         16         16          1      0.967      0.995      0.888\n",
            "                    3C         17         17          1      0.861      0.995      0.873\n",
            "                    3D         15         15          1      0.969      0.995       0.83\n",
            "                    3H         18         18       0.87      0.889      0.966      0.871\n",
            "                    3S         16         16      0.998          1      0.995      0.968\n",
            "                    4C         17         17      0.986          1      0.995       0.89\n",
            "                    4D         15         15      0.998          1      0.995      0.782\n",
            "                    4H         18         18          1      0.871      0.989      0.938\n",
            "                    4S         16         16          1      0.979      0.995      0.967\n",
            "                    5C         17         17      0.961      0.941      0.992      0.869\n",
            "                    5D         15         15      0.971          1      0.995      0.824\n",
            "                    5H         18         18      0.982          1      0.995      0.974\n",
            "                    5S         15         15      0.992          1      0.995      0.911\n",
            "                    6C         15         15          1      0.945      0.995      0.866\n",
            "                    6D         15         15      0.983          1      0.995      0.837\n",
            "                    6H         16         16      0.929      0.823      0.934      0.872\n",
            "                    7C         16         16      0.991          1      0.995      0.981\n",
            "                    7D         15         15      0.982          1      0.995      0.977\n",
            "                    7H         15         15      0.966          1      0.995       0.88\n",
            "                    7S         15         15      0.989          1      0.995      0.868\n",
            "                    8C         16         16      0.919      0.938      0.943      0.925\n",
            "                    8D         15         15      0.976      0.933      0.991      0.991\n",
            "                    8H         15         15          1      0.829      0.991      0.864\n",
            "                    8S         15         15          1      0.974      0.995      0.857\n",
            "                    9C         16         16          1      0.792      0.984       0.89\n",
            "                    9D         15         15      0.877          1      0.995      0.986\n",
            "                    9H         15         15      0.937       0.99      0.991      0.879\n",
            "                    9S         15         15      0.962          1      0.995      0.873\n",
            "                   10C         16         16      0.922      0.875      0.948      0.918\n",
            "                   10D         16         16      0.951          1      0.995      0.945\n",
            "                   10H         17         17      0.981          1      0.995      0.873\n",
            "                   10S         15         15          1      0.982      0.995      0.894\n",
            "                    JC         18         18       0.93          1      0.995      0.975\n",
            "                    JD         16         16      0.981          1      0.995      0.904\n",
            "                    JH         17         17      0.987          1      0.995      0.868\n",
            "                    JS         15         15      0.996          1      0.995      0.699\n",
            "                    QC         18         18          1      0.895      0.995      0.893\n",
            "                    QD         16         16       0.99          1      0.995      0.954\n",
            "                    QH         17         17      0.993          1      0.995      0.885\n",
            "                    QS         15         15          1       0.99      0.995      0.871\n",
            "                    KC         18         18          1      0.949      0.995      0.958\n",
            "                    KD         16         16      0.976      0.938      0.975      0.939\n",
            "                    KH         17         17      0.981          1      0.995      0.875\n",
            "                    KS         15         15      0.982          1      0.995      0.882\n",
            "                    AC         18         18      0.934          1      0.963      0.919\n",
            "                    AD         16         16      0.983          1      0.995      0.979\n",
            "                    AH         17         17      0.986          1      0.995      0.885\n",
            "                    AS         15         15      0.982          1      0.995       0.87\n",
            "Speed: 0.2ms preprocess, 2.8ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/cards/models/card_detection2\u001b[0m\n",
            "Training completed. Results saved to /content/drive/MyDrive/cards/models/card_detection2\n",
            "Best model saved as /content/drive/MyDrive/cards/models/card_detection2/weights/best.pt\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# Path to the updated data YAML file\n",
        "data_path = '/content/drive/MyDrive/cards/colab_data.yaml'\n",
        "\n",
        "# Path for saving results\n",
        "project_dir = '/content/drive/MyDrive/cards/models'\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "# Initialize model\n",
        "model_size = 'n'  # Can be 'n', 's', 'm', 'l', or 'x'\n",
        "model = YOLO(f'yolov8{model_size}.pt')\n",
        "\n",
        "# Train the model\n",
        "print(f\"Training with data config: {data_path}\")\n",
        "results = model.train(\n",
        "    data=data_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    project=project_dir,\n",
        "    name='card_detection'\n",
        ")\n",
        "\n",
        "# Print information about the training results\n",
        "print(f\"Training completed. Results saved to {results.save_dir}\")\n",
        "print(f\"Best model saved as {os.path.join(results.save_dir, 'weights', 'best.pt')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skV4IFnyQg6U"
      },
      "source": [
        "### 🔎 Inspect Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lWSrIFe9QpDz",
        "outputId": "ecf5d21e-9111-4d03-ca5a-ff5e5c6cf03f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running evaluation on the test set...\n",
            "Ultralytics 8.3.100 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,015,788 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/cards/dataset/test/labels.cache... 128 images, 0 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        128        543      0.962      0.963      0.987      0.901\n",
            "                    2C         11         11      0.977          1      0.995       0.87\n",
            "                    2D         10         10          1      0.924      0.995      0.873\n",
            "                    2H         12         12      0.971          1      0.995      0.964\n",
            "                    2S         10         10      0.983          1      0.995      0.878\n",
            "                    3C         11         11      0.944          1      0.995      0.863\n",
            "                    3D         10         10          1      0.763      0.995      0.743\n",
            "                    3H         12         12      0.917      0.916       0.97      0.918\n",
            "                    3S         10         10       0.97          1      0.995      0.915\n",
            "                    4C         11         11      0.973          1      0.995       0.88\n",
            "                    4D         10         10      0.976        0.9      0.935      0.785\n",
            "                    4H         12         12          1      0.997      0.995      0.995\n",
            "                    4S         10         10      0.984          1      0.995      0.927\n",
            "                    5C         11         11      0.936      0.909      0.988      0.898\n",
            "                    5D         10         10      0.889          1      0.995      0.781\n",
            "                    5H         12         12       0.97      0.917      0.968      0.959\n",
            "                    5S         10         10      0.895          1      0.995      0.974\n",
            "                    6C         11         11      0.983          1      0.995      0.866\n",
            "                    6D         10         10      0.988          1      0.995       0.88\n",
            "                    6H         11         11          1      0.734      0.901      0.845\n",
            "                    7C         10         10      0.971          1      0.995      0.971\n",
            "                    7D         10         10          1      0.921      0.995      0.941\n",
            "                    7H         11         11      0.965          1      0.995      0.931\n",
            "                    7S         10         10      0.994          1      0.995      0.815\n",
            "                    8C         11         11      0.912      0.946       0.98      0.939\n",
            "                    8D         10         10      0.822          1      0.977      0.977\n",
            "                    8H         11         11       0.98          1      0.995      0.889\n",
            "                    8S         10         10          1       0.89      0.995      0.849\n",
            "                    9C         11         11      0.764      0.591        0.9      0.871\n",
            "                    9D         10         10      0.979        0.9      0.986      0.967\n",
            "                    9H         11         11      0.988          1      0.995      0.851\n",
            "                    9S         10         10      0.937          1      0.995      0.887\n",
            "                   10C         11         11      0.864      0.909      0.927      0.839\n",
            "                   10D         10         10      0.975          1      0.995      0.971\n",
            "                   10H         11         11      0.979          1      0.995      0.872\n",
            "                   10S         10         10      0.977          1      0.995       0.87\n",
            "                    JC         12         12      0.976          1      0.995      0.946\n",
            "                    JD         10         10       0.98          1      0.995       0.82\n",
            "                    JH         11         11      0.983          1      0.995      0.918\n",
            "                    JS         10         10      0.978          1      0.995      0.863\n",
            "                    QC         12         12      0.935          1      0.995      0.913\n",
            "                    QD         10         10      0.971          1      0.995      0.995\n",
            "                    QH         11         11      0.977          1      0.995      0.897\n",
            "                    QS         10         10          1      0.957      0.995      0.912\n",
            "                    KC         12         12      0.974      0.917      0.989      0.921\n",
            "                    KD         10         10      0.971          1      0.995      0.985\n",
            "                    KH         11         11      0.978          1      0.995      0.921\n",
            "                    KS         10         10      0.981          1      0.995      0.867\n",
            "                    AC         12         12       0.98          1      0.995      0.954\n",
            "                    AD         10         10      0.973          1      0.995      0.995\n",
            "                    AH         11         11      0.978          1      0.995      0.905\n",
            "                    AS         10         10      0.972          1      0.995      0.897\n",
            "Speed: 3.6ms preprocess, 4.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "\n",
            "Test Set Metrics:\n",
            "mAP50: 0.9867\n",
            "mAP50-95: 0.9013\n",
            "Precision: 0.9622\n",
            "Recall: 0.9626\n",
            "\n",
            "Generating detailed per-class analysis...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/128 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 57.9ms\n",
            "Speed: 4.7ms preprocess, 57.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/128 [00:00<00:15,  8.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 14.8ms\n",
            "Speed: 4.1ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 4H, 1 QC, 14.3ms\n",
            "Speed: 5.0ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 1 AC, 12.8ms\n",
            "Speed: 4.1ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 4/128 [00:00<00:07, 17.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2H, 1 JC, 2 KCs, 1 AC, 14.3ms\n",
            "Speed: 4.8ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 2 ACs, 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 1 8H, 1 9H, 15.3ms\n",
            "Speed: 4.1ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 7/128 [00:00<00:05, 20.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 2 ACs, 15.7ms\n",
            "Speed: 4.1ms preprocess, 15.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 3S, 1 4S, 1 JD, 10.1ms\n",
            "Speed: 4.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 2 9Ss, 10.7ms\n",
            "Speed: 4.3ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 10/128 [00:00<00:05, 21.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QD, 1 QS, 1 KD, 1 KH, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 3S, 1 4S, 1 JD, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 12.3ms\n",
            "Speed: 4.0ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 13/128 [00:00<00:04, 23.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 2 ACs, 13.0ms\n",
            "Speed: 4.6ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 1 10C, 12.2ms\n",
            "Speed: 4.9ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 3S, 1 4S, 1 JD, 12.2ms\n",
            "Speed: 4.0ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 16/128 [00:00<00:04, 23.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KS, 1 AS, 9.3ms\n",
            "Speed: 4.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 5S, 2 8Ds, 1 9D, 15.4ms\n",
            "Speed: 5.7ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 3S, 1 4S, 1 JD, 14.0ms\n",
            "Speed: 7.3ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 19/128 [00:00<00:04, 22.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 11.9ms\n",
            "Speed: 4.7ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 2 8Cs, 1 9C, 1 10C, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 22/128 [00:00<00:04, 23.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QH, 1 KD, 1 KH, 11.9ms\n",
            "Speed: 4.0ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 13.8ms\n",
            "Speed: 3.7ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|█▉        | 25/128 [00:01<00:04, 24.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 6.6ms\n",
            "Speed: 3.4ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 3 KDs, 7.0ms\n",
            "Speed: 3.4ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QS, 1 KH, 1 AH, 7.7ms\n",
            "Speed: 4.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 2 KDs, 6.7ms\n",
            "Speed: 3.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 29/128 [00:01<00:03, 28.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 6.7ms\n",
            "Speed: 3.1ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 5S, 1 7D, 3 8Ds, 1 9D, 6.5ms\n",
            "Speed: 3.3ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 3Cs, 1 4C, 1 5C, 1 JH, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 2 QSs, 1 KS, 1 AS, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 33/128 [00:01<00:03, 31.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 2 3Cs, 1 4C, 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 2 KDs, 1 AD, 8.8ms\n",
            "Speed: 3.6ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 37/128 [00:01<00:02, 32.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 7C, 1 10D, 3 KDs, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 4S, 1 8D, 1 JD, 7.1ms\n",
            "Speed: 3.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 3Hs, 1 4H, 1 5H, 2 QCs, 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QH, 1 KD, 1 KH, 1 AH, 6.7ms\n",
            "Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 41/128 [00:01<00:02, 34.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2H, 1 JC, 2 KCs, 2 ACs, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 10S, 1 QS, 1 KS, 1 AS, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 2 QDs, 1 KD, 6.9ms\n",
            "Speed: 3.1ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QH, 1 KH, 1 AH, 7.5ms\n",
            "Speed: 3.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 45/128 [00:01<00:02, 35.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 6.4ms\n",
            "Speed: 2.9ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 7Ds, 1 8D, 1 9D, 6.7ms\n",
            "Speed: 3.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 1 8H, 1 9H, 6.7ms\n",
            "Speed: 3.6ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 1 KD, 1 AD, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 6.5ms\n",
            "Speed: 3.3ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 50/128 [00:01<00:02, 37.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 4H, 1 5H, 1 QC, 7.0ms\n",
            "Speed: 3.4ms preprocess, 7.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 2 QHs, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 5S, 1 7D, 1 8D, 1 9D, 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 54/128 [00:01<00:01, 37.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 5S, 1 7D, 2 8Ds, 1 9D, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 1 10C, 7.6ms\n",
            "Speed: 3.4ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 1 8H, 1 9H, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 7.2ms\n",
            "Speed: 3.4ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 58/128 [00:01<00:01, 35.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 8.3ms\n",
            "Speed: 4.2ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 2 7Hs, 1 8H, 1 9H, 7.2ms\n",
            "Speed: 3.6ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 3 KDs, 7.2ms\n",
            "Speed: 3.7ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 7.3ms\n",
            "Speed: 3.6ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 62/128 [00:02<00:01, 35.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 5S, 2 7Ds, 1 8D, 2 9Ds, 6.9ms\n",
            "Speed: 3.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 6Hs, 1 8C, 1 10C, 6.8ms\n",
            "Speed: 3.5ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 6.9ms\n",
            "Speed: 3.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QH, 1 KH, 1 AH, 8.0ms\n",
            "Speed: 3.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 66/128 [00:02<00:01, 36.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 8C, 1 9C, 1 10C, 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 70/128 [00:02<00:01, 36.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 2 7Cs, 1 QD, 1 KC, 2 KDs, 6.8ms\n",
            "Speed: 3.6ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 2 ACs, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 7Ds, 1 8D, 1 9D, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 6.5ms\n",
            "Speed: 3.5ms preprocess, 6.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 74/128 [00:02<00:01, 36.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 5S, 3 8Ds, 1 9D, 6.5ms\n",
            "Speed: 3.4ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 1 3S, 1 JD, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 2 8Hs, 1 9H, 7.0ms\n",
            "Speed: 3.4ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 10H, 2 QHs, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 78/128 [00:02<00:01, 37.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 2 KDs, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 2 ACs, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 82/128 [00:02<00:01, 38.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2S, 2 3Ss, 1 4S, 1 JD, 6.5ms\n",
            "Speed: 3.6ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 7.3ms\n",
            "Speed: 3.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QS, 1 KH, 1 AH, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 2 8Cs, 1 9C, 1 10C, 7.2ms\n",
            "Speed: 3.5ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 86/128 [00:02<00:01, 37.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KH, 1 KS, 1 AS, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 7C, 1 10D, 1 QD, 2 KDs, 7.3ms\n",
            "Speed: 3.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 1 8H, 1 9H, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 2 KCs, 1 AC, 8.5ms\n",
            "Speed: 3.5ms preprocess, 8.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 90/128 [00:02<00:01, 37.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2S, 2 3Ss, 1 4S, 7.1ms\n",
            "Speed: 3.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 2H, 1 10S, 1 QS, 1 KC, 1 KS, 1 AS, 7.1ms\n",
            "Speed: 3.8ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 2 QSs, 1 KS, 1 AS, 12.9ms\n",
            "Speed: 3.8ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 1 8H, 1 9H, 7.6ms\n",
            "Speed: 3.5ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 94/128 [00:02<00:00, 35.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 2 9Cs, 1 10C, 7.1ms\n",
            "Speed: 3.5ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 3 8Hs, 7.2ms\n",
            "Speed: 3.8ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6C, 1 7H, 2 8Hs, 7.0ms\n",
            "Speed: 3.7ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 98/128 [00:03<00:00, 34.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 9.1ms\n",
            "Speed: 3.7ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KS, 1 AS, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 2 5Ds, 1 JS, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 102/128 [00:03<00:00, 35.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 1 10C, 7.9ms\n",
            "Speed: 4.3ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 2 3Ss, 1 4S, 1 JD, 6.8ms\n",
            "Speed: 3.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KS, 1 AS, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 1 10C, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 106/128 [00:03<00:00, 35.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 1 AC, 6.6ms\n",
            "Speed: 3.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 2 10Cs, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 7.3ms\n",
            "Speed: 3.7ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 2 3Hs, 1 4H, 1 5H, 1 QC, 7.5ms\n",
            "Speed: 3.8ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 110/128 [00:03<00:00, 36.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 7.1ms\n",
            "Speed: 3.6ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 5S, 1 7D, 1 8D, 1 9D, 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3H, 1 4H, 1 5H, 1 QC, 10.3ms\n",
            "Speed: 4.4ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QH, 1 QS, 1 KH, 1 AH, 1 AS, 7.2ms\n",
            "Speed: 3.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 114/128 [00:03<00:00, 36.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 3C, 1 4C, 1 5C, 1 JH, 6.7ms\n",
            "Speed: 3.6ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3C, 2 4Cs, 1 5C, 8.6ms\n",
            "Speed: 3.5ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6D, 1 7S, 1 8S, 1 9S, 7.0ms\n",
            "Speed: 3.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KS, 1 AS, 6.7ms\n",
            "Speed: 3.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 118/128 [00:03<00:00, 36.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 5S, 1 7D, 1 8D, 1 9D, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 KC, 3 ACs, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2C, 1 10H, 1 QS, 1 KD, 6.6ms\n",
            "Speed: 3.7ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2S, 2 3Ss, 1 4S, 7.0ms\n",
            "Speed: 3.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 122/128 [00:03<00:00, 37.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6C, 2 7Hs, 1 8H, 1 9H, 6.7ms\n",
            "Speed: 3.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2D, 1 10S, 1 QS, 1 KS, 1 AS, 6.6ms\n",
            "Speed: 3.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 6H, 1 8C, 1 9C, 1 10C, 7.0ms\n",
            "Speed: 3.5ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 2H, 1 JC, 1 AC, 6.9ms\n",
            "Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 126/128 [00:03<00:00, 37.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 6C, 1 7H, 2 8Hs, 1 9H, 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 3D, 1 4D, 1 5D, 1 JS, 6.4ms\n",
            "Speed: 3.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 128/128 [00:03<00:00, 33.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detection Statistics by Card Class:\n",
            "   class  count  avg_conf  min_conf  max_conf\n",
            "44    KD     25  0.851544  0.433099  0.991759\n",
            "35    AC     20  0.710567  0.340189  0.998641\n",
            "28    8D     17  0.827122  0.279368  0.995602\n",
            "50    QS     17  0.763561  0.333591  0.976875\n",
            "43    KC     16  0.667315  0.265907  0.943943\n",
            "29    8H     16  0.804629  0.415607  0.979249\n",
            "25    7H     13  0.799803  0.285822  0.965385\n",
            "27    8C     13  0.855007  0.401960  0.986221\n",
            "11    3S     13  0.800678  0.250419  0.982648\n",
            "8     3C     13  0.791840  0.252823  0.989393\n",
            "47    QC     13  0.934344  0.516783  0.988344\n",
            "6     2H     13  0.938782  0.622164  0.991103\n",
            "12    4C     12  0.936012  0.792343  0.971692\n",
            "0    10C     12  0.903854  0.323049  0.992501\n",
            "14    4H     12  0.931471  0.665862  0.994171\n",
            "39    JC     12  0.955106  0.849611  0.994928\n",
            "10    3H     12  0.866857  0.449136  0.993323\n",
            "18    5H     11  0.937749  0.627981  0.987545\n",
            "2    10H     11  0.799694  0.473704  0.959716\n",
            "38    AS     11  0.661453  0.377208  0.946706\n",
            "31    9C     11  0.848602  0.519082  0.986275\n",
            "48    QD     11  0.735456  0.384392  0.973995\n",
            "32    9D     11  0.724609  0.302422  0.986399\n",
            "24    7D     11  0.702122  0.278465  0.941683\n",
            "20    6C     11  0.723485  0.255609  0.944148\n",
            "23    7C     11  0.931710  0.734041  0.988742\n",
            "22    6H     11  0.725368  0.301937  0.935083\n",
            "34    9S     11  0.913397  0.291180  0.989761\n",
            "17    5D     11  0.937648  0.782910  0.985518\n",
            "3    10S     10  0.925572  0.785539  0.975950\n",
            "13    4D     10  0.856956  0.346997  0.969089\n",
            "7     2S     10  0.883561  0.448233  0.988424\n",
            "4     2C     10  0.798824  0.411915  0.949405\n",
            "9     3D     10  0.795592  0.340237  0.977905\n",
            "16    5C     10  0.958659  0.922320  0.979776\n",
            "21    6D     10  0.887121  0.748641  0.952575\n",
            "46    KS     10  0.706414  0.282084  0.928109\n",
            "26    7S     10  0.940098  0.755890  0.986612\n",
            "42    JS     10  0.961545  0.924563  0.984484\n",
            "30    8S     10  0.945533  0.870511  0.987981\n",
            "15    4S      9  0.803453  0.638394  0.917452\n",
            "1    10D      9  0.961609  0.931124  0.995687\n",
            "5     2D      9  0.950010  0.923892  0.985759\n",
            "49    QH      9  0.577865  0.290606  0.748279\n",
            "33    9H      9  0.720954  0.296837  0.890565\n",
            "45    KH      9  0.809010  0.395807  0.991785\n",
            "41    JH      9  0.828179  0.405108  0.928454\n",
            "19    5S      8  0.733921  0.291445  0.909131\n",
            "40    JD      8  0.787506  0.492052  0.984940\n",
            "37    AH      6  0.682698  0.288337  0.926949\n",
            "36    AD      2  0.415149  0.391517  0.438782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Run this cell to evaluate your model on the test set\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Path to your trained model\n",
        "model_path = '/content/drive/MyDrive/cards/models/card_detection2/weights/best.pt'\n",
        "\n",
        "# Path to test images (from your updated YAML file)\n",
        "test_images_path = '/content/drive/MyDrive/cards/dataset/test/images'\n",
        "\n",
        "# Load the model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "print(\"Running evaluation on the test set...\")\n",
        "test_results = model.val(data='/content/drive/MyDrive/cards/colab_data.yaml', split='test')\n",
        "\n",
        "# Display test metrics\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"mAP50: {test_results.box.map50:.4f}\")  # mAP at IoU=0.5\n",
        "print(f\"mAP50-95: {test_results.box.map:.4f}\")  # mAP at IoU=0.5:0.95\n",
        "print(f\"Precision: {test_results.box.mp:.4f}\")  # mean precision\n",
        "print(f\"Recall: {test_results.box.mr:.4f}\")     # mean recall\n",
        "\n",
        "# Create a more detailed analysis by class (for selected classes)\n",
        "print(\"\\nGenerating detailed per-class analysis...\")\n",
        "\n",
        "# Get list of test images\n",
        "test_images = [f for f in os.listdir(test_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Collect predictions for analysis\n",
        "all_preds = []\n",
        "all_conf = []\n",
        "all_class_names = []\n",
        "\n",
        "# Process all test images\n",
        "for img_name in tqdm(test_images):\n",
        "    img_path = os.path.join(test_images_path, img_name)\n",
        "\n",
        "    # Read image\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run prediction\n",
        "    results = model(img_rgb)\n",
        "\n",
        "    # Extract results\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            cls_name = model.names[cls_id]\n",
        "            conf = float(box.conf[0])\n",
        "\n",
        "            all_preds.append(cls_name)\n",
        "            all_conf.append(conf)\n",
        "            all_class_names.append(cls_name)\n",
        "\n",
        "# Create a DataFrame for analysis\n",
        "df = pd.DataFrame({\n",
        "    'class': all_preds,\n",
        "    'confidence': all_conf\n",
        "})\n",
        "\n",
        "# Group by class\n",
        "class_stats = df.groupby('class').agg({\n",
        "    'confidence': ['count', 'mean', 'min', 'max']\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten the column names\n",
        "class_stats.columns = ['class', 'count', 'avg_conf', 'min_conf', 'max_conf']\n",
        "\n",
        "# Sort by count (descending)\n",
        "class_stats = class_stats.sort_values('count', ascending=False)\n",
        "\n",
        "# Display the table\n",
        "print(\"\\nDetection Statistics by Card Class:\")\n",
        "print(class_stats)\n",
        "\n",
        "# Plot the distribution of predictions by card type\n",
        "plt.figure(figsize=(14, 8))\n",
        "top_classes = class_stats.head(10)['class'].values\n",
        "plt.bar(top_classes, class_stats.head(10)['count'].values)\n",
        "plt.title('Top 10 Most Detected Cards')\n",
        "plt.xlabel('Card Class')\n",
        "plt.ylabel('Number of Detections')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot confidence distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['confidence'], bins=20, alpha=0.7)\n",
        "plt.title('Confidence Score Distribution')\n",
        "plt.xlabel('Confidence')\n",
        "plt.ylabel('Count')\n",
        "plt.axvline(0.5, color='red', linestyle='--', label='Typical Threshold (0.5)')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
